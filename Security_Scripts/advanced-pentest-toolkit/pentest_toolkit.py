#!/usr/bin/env python3
"""Advanced Penetration Testing Toolkit utilities.

This module exposes a tiny automation layer around Metasploit's RPC interface
and now also provides a CLI helper that can run single exploits or execute
batch definitions from JSON.  Random delays and optional dry-run capabilities
help model stealthier operations while still being testable in CI systems where
Metasploit is not available.

Use only on systems you are authorized to test.
"""
from __future__ import annotations

import argparse
import json
import logging
import queue
import random
import threading
import time
from datetime import datetime
from dataclasses import dataclass, field
from pathlib import Path
from typing import Iterable, List, Sequence

try:
    from metasploit.msfrpc import MsfRpcClient  # type: ignore
except Exception:  # pragma: no cover - library may not be installed
    MsfRpcClient = None  # type: ignore

try:  # Optional machine learning dependencies
    from sklearn.ensemble import RandomForestClassifier  # type: ignore
    from sklearn.pipeline import Pipeline  # type: ignore
    from sklearn.preprocessing import StandardScaler  # type: ignore
except Exception:  # pragma: no cover - scikit-learn is optional
    RandomForestClassifier = None  # type: ignore
    Pipeline = None  # type: ignore
    StandardScaler = None  # type: ignore

try:  # joblib is distributed with scikit-learn
    import joblib  # type: ignore
except Exception:  # pragma: no cover - optional dependency
    joblib = None  # type: ignore


@dataclass
class AttackTask:
    """Describe a single exploit invocation."""

    target: str
    exploit: str
    payload: str
    options: dict[str, str] = field(default_factory=dict)


class AttackAutomator:
    """Wrapper around Metasploit's RPC client to automate exploit runs."""

    def __init__(
        self,
        password: str,
        server: str = "127.0.0.1",
        port: int = 55553,
        ssl: bool = True,
        *,
        min_delay: float = 0.5,
        max_delay: float = 2.5,
    ) -> None:
        if MsfRpcClient is None:
            raise RuntimeError("metasploit.msfrpc module not available")
        self.client = MsfRpcClient(password, server=server, port=port, ssl=ssl)
        self.logger = logging.getLogger(__name__)
        self.min_delay = max(min_delay, 0.0)
        self.max_delay = max(max_delay, self.min_delay)

    def execute_task(self, task: AttackTask) -> str:
        """Run an exploit against a target with random delays for evasion."""

        console = self.client.consoles.console()
        self.logger.info("Launching %s against %s", task.exploit, task.target)
        console.write(f"use {task.exploit}\n")
        console.write(f"set RHOSTS {task.target}\n")
        console.write(f"set PAYLOAD {task.payload}\n")
        for key, value in task.options.items():
            console.write(f"set {key} {value}\n")
        console.write("run\n")
        self._random_delay()
        result = console.read().get("data", "")
        console.destroy()
        return result

    def _random_delay(self) -> None:
        if self.max_delay == 0:
            return
        time.sleep(random.uniform(self.min_delay, self.max_delay))


class DryRunAutomator:
    """Fallback executor for environments without Metasploit."""

    def __init__(self) -> None:
        self.logger = logging.getLogger(__name__)

    def execute_task(self, task: AttackTask) -> str:  # pragma: no cover - simple logging
        summary = (
            f"DRY RUN -> exploit={task.exploit}, payload={task.payload}, target={task.target}, "
            f"options={task.options or '{}'}"
        )
        self.logger.info(summary)
        # Return summary so batch operations still have deterministic output
        return summary


class SimpleRiskModel:
    """Lightweight heuristic model for severity scoring when sklearn is absent."""

    weights = (0.35, 0.35, 0.2, 0.1)

    def __init__(self) -> None:
        self.feature_mins = [0.0, 0.0, 0.0, 0.0]
        self.feature_maxs = [1.0, 1.0, 1.0, 1.0]

    def fit(self, features: List[list[float]], labels: List[int]) -> None:
        if not features:
            raise ValueError("Dataset must not be empty")
        cols = list(zip(*features))
        self.feature_mins = [min(col) for col in cols]
        self.feature_maxs = [max(col) or 1.0 for col in cols]

    def _normalize(self, vector: list[float]) -> list[float]:
        normalized: list[float] = []
        for value, min_v, max_v in zip(vector, self.feature_mins, self.feature_maxs):
            if max_v == min_v:
                normalized.append(0.0)
            else:
                normalized.append((value - min_v) / (max_v - min_v))
        return normalized

    def predict(self, rows: List[list[float]]) -> tuple[list[int], list[float]]:
        predictions: list[int] = []
        confidences: list[float] = []
        for row in rows:
            normalized = self._normalize(row)
            score = sum(weight * value for weight, value in zip(self.weights, normalized))
            if score >= 0.66:
                predictions.append(2)
            elif score >= 0.33:
                predictions.append(1)
            else:
                predictions.append(0)
            confidences.append(score)
        return predictions, confidences

    def score(self, features: List[list[float]], labels: List[int]) -> float:
        predictions, _ = self.predict(features)
        correct = sum(1 for pred, label in zip(predictions, labels) if pred == label)
        return correct / len(labels)

    def to_dict(self) -> dict[str, list[float]]:
        return {"mins": self.feature_mins, "maxs": self.feature_maxs}

    def load_state(self, payload: dict[str, list[float]]) -> None:
        self.feature_mins = payload.get("mins", self.feature_mins)
        self.feature_maxs = payload.get("maxs", self.feature_maxs)


class ThreatPredictor:
    """Trainable vulnerability severity predictor with optional sklearn backend."""

    FEATURE_NAMES = ("open_ports", "vuln_count", "exposure_score", "criticality")
    LABEL_TO_INDEX = {"low": 0, "medium": 1, "high": 2}
    INDEX_TO_LABEL = {value: key for key, value in LABEL_TO_INDEX.items()}

    def __init__(self, model_path: Path | None = None) -> None:
        self.model_path = model_path
        self.model: object | None = None
        self.backend = "simple"
        if self.model_path and self.model_path.exists():
            self.load(self.model_path)

    def _vectorize(self, entry: dict[str, float]) -> list[float]:
        vector: list[float] = []
        for feature in self.FEATURE_NAMES:
            if feature not in entry:
                raise ValueError(f"Missing feature '{feature}'.")
            try:
                vector.append(float(entry[feature]))
            except (TypeError, ValueError) as exc:
                raise ValueError(f"Feature '{feature}' must be numeric") from exc
        return vector

    def _load_dataset(self, dataset_path: Path) -> tuple[List[list[float]], List[int]]:
        payload = json.loads(dataset_path.read_text(encoding="utf-8"))
        if not isinstance(payload, list):
            raise ValueError("Dataset must be a JSON list")
        features: List[list[float]] = []
        labels: List[int] = []
        for row in payload:
            if not isinstance(row, dict):
                raise ValueError("Each dataset entry must be a JSON object")
            vector = self._vectorize(row)
            label_raw = str(row.get("label", "")).lower()
            if label_raw not in self.LABEL_TO_INDEX:
                raise ValueError("Each entry must include a label of low, medium, or high")
            features.append(vector)
            labels.append(self.LABEL_TO_INDEX[label_raw])
        return features, labels

    def train(self, dataset_path: Path) -> dict[str, float]:
        features, labels = self._load_dataset(dataset_path)
        if RandomForestClassifier and Pipeline and StandardScaler:
            pipeline = Pipeline(
                [
                    ("scaler", StandardScaler()),
                    ("model", RandomForestClassifier(n_estimators=200, random_state=1337)),
                ]
            )
            pipeline.fit(features, labels)
            self.model = pipeline
            self.backend = "sklearn"
            accuracy = float(pipeline.score(features, labels))
        else:
            heuristic = SimpleRiskModel()
            heuristic.fit(features, labels)
            self.model = heuristic
            self.backend = "simple"
            accuracy = float(heuristic.score(features, labels))
        return {"samples": len(labels), "accuracy": accuracy, "backend": self.backend}

    def ensure_model(self) -> None:
        if self.model is None:
            raise RuntimeError("No ML model is loaded. Train a model or supply --ml-model.")

    def predict(self, features: dict[str, float]) -> tuple[str, float]:
        self.ensure_model()
        vector = self._vectorize(features)
        if self.backend == "sklearn" and Pipeline and hasattr(self.model, "predict"):
            pipeline: Pipeline = self.model  # type: ignore[assignment]
            prediction = int(pipeline.predict([vector])[0])
            confidence = 0.0
            if hasattr(pipeline, "predict_proba"):
                probabilities = pipeline.predict_proba([vector])[0]
                confidence = float(probabilities[prediction])
        else:
            heuristic: SimpleRiskModel = self.model  # type: ignore[assignment]
            prediction, confidences = heuristic.predict([vector])
            confidence = float(confidences[0])
            prediction = int(prediction[0])
        return self.INDEX_TO_LABEL[prediction], confidence

    def save(self, destination: Path) -> None:
        self.ensure_model()
        if self.backend == "sklearn" and joblib:
            joblib.dump({"model": self.model, "backend": self.backend}, destination)
        elif self.backend == "simple":
            heuristic: SimpleRiskModel = self.model  # type: ignore[assignment]
            payload = {"backend": "simple", "state": heuristic.to_dict()}
            destination.write_text(json.dumps(payload, indent=2), encoding="utf-8")
        else:
            raise RuntimeError("Saving sklearn models requires joblib to be installed")

    def load(self, source: Path) -> None:
        if not source.exists():
            raise FileNotFoundError(source)
        if source.suffix in {".json", ""}:
            payload = json.loads(source.read_text(encoding="utf-8"))
            backend = payload.get("backend")
            if backend != "simple":
                raise ValueError("JSON state files only support the simple backend")
            heuristic = SimpleRiskModel()
            heuristic.load_state(payload.get("state", {}))
            self.model = heuristic
            self.backend = "simple"
            return
        if not joblib:
            raise RuntimeError("joblib is required to load sklearn models")
        payload = joblib.load(source)
        backend = payload.get("backend", "sklearn")
        self.model = payload["model"]
        self.backend = backend

def _parse_options(option_pairs: Sequence[str]) -> dict[str, str]:
    options: dict[str, str] = {}
    for raw in option_pairs:
        if "=" not in raw:
            raise ValueError(f"Invalid option '{raw}'. Expected KEY=VALUE format.")
        key, value = raw.split("=", 1)
        key = key.strip().upper()
        value = value.strip()
        if not key or not value:
            raise ValueError(f"Invalid option '{raw}'. Empty key/value not allowed.")
        options[key] = value
    return options


def _parse_feature_pairs(pairs: Sequence[str]) -> dict[str, float]:
    features: dict[str, float] = {}
    for raw in pairs:
        if "=" not in raw:
            raise ValueError(f"Invalid feature '{raw}'. Expected KEY=VALUE format.")
        key, value = raw.split("=", 1)
        key = key.strip().lower()
        value = value.strip()
        if not key or not value:
            raise ValueError(f"Invalid feature '{raw}'. Empty key/value not allowed.")
        try:
            features[key] = float(value)
        except ValueError as exc:
            raise ValueError(f"Feature '{key}' must be numeric") from exc
    return features


def _load_tasks_from_file(path: Path) -> List[AttackTask]:
    payload = json.loads(path.read_text())
    if not isinstance(payload, list):
        raise ValueError("Task file must contain a list of task definitions")
    tasks: List[AttackTask] = []
    for entry in payload:
        if not isinstance(entry, dict):
            raise ValueError("Each task entry must be a JSON object")
        try:
            task = AttackTask(
                target=entry["target"],
                exploit=entry["exploit"],
                payload=entry["payload"],
                options={k.upper(): str(v) for k, v in entry.get("options", {}).items()},
            )
        except KeyError as exc:
            raise ValueError(f"Missing required field in task definition: {exc}") from exc
        tasks.append(task)
    return tasks


def _build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="Automate Metasploit RPC operations with optional dry runs.")
    parser.add_argument("--password", help="Metasploit RPC password. Optional in --dry-run mode.")
    parser.add_argument("--server", default="127.0.0.1", help="Metasploit RPC server address.")
    parser.add_argument("--port", default=55553, type=int, help="Metasploit RPC port (default: 55553).")
    parser.add_argument("--no-ssl", dest="ssl", action="store_false", help="Disable SSL for RPC communication.")
    parser.add_argument("--dry-run", action="store_true", help="Do not execute commands, just log actions.")
    parser.add_argument("--min-delay", type=float, default=0.5, help="Minimum delay between tasks (seconds).")
    parser.add_argument("--max-delay", type=float, default=2.5, help="Maximum delay between tasks (seconds).")
    parser.add_argument("--output", type=Path, help="Optional JSON file to store execution results.")
    parser.add_argument("--gui", action="store_true", help="Launch the graphical interface instead of the CLI runner.")
    parser.add_argument("--ml-dataset", type=Path, help="JSON dataset for training the threat predictor.")
    parser.add_argument("--ml-model", type=Path, help="Optional path to save or load the machine learning model.")
    parser.add_argument(
        "--ml-predict",
        action="append",
        default=[],
        metavar="KEY=VALUE",
        help="Feature pairs (open_ports, vuln_count, exposure_score, criticality) for inline predictions.",
    )

    task_group = parser.add_mutually_exclusive_group(required=False)
    task_group.add_argument(
        "--task",
        nargs=3,
        metavar=("TARGET", "EXPLOIT", "PAYLOAD"),
        help="Execute a single exploit run with inline parameters.",
    )
    task_group.add_argument(
        "--task-file",
        type=Path,
        help="Path to a JSON file describing a list of tasks.",
    )
    parser.add_argument(
        "--option",
        action="append",
        default=[],
        metavar="KEY=VALUE",
        help="Additional Metasploit options for the inline --task version.",
    )
    return parser


def _select_executor(args: argparse.Namespace):
    if args.dry_run:
        return DryRunAutomator()
    if args.password is None:
        raise SystemExit("--password is required unless --dry-run is supplied")
    return AttackAutomator(
        args.password,
        server=args.server,
        port=args.port,
        ssl=args.ssl,
        min_delay=args.min_delay,
        max_delay=args.max_delay,
    )


def _collect_tasks(args: argparse.Namespace) -> List[AttackTask]:
    if args.task:
        options = _parse_options(args.option)
        return [AttackTask(target=args.task[0], exploit=args.task[1], payload=args.task[2], options=options)]
    if args.task_file:
        return _load_tasks_from_file(args.task_file)
    raise SystemExit("Either --task or --task-file must be supplied")


def launch_gui(predictor: ThreatPredictor | None = None) -> None:
    gui = PentestGUI(predictor=predictor)
    gui.run()


class PentestGUI:
    """Tkinter interface for launching tasks and ML workflows."""

    def __init__(self, predictor: ThreatPredictor | None = None) -> None:
        try:  # Imported lazily so CLI environments without Tk still work
            import tkinter as tk
            from tkinter import filedialog, messagebox, ttk
        except ImportError as exc:  # pragma: no cover - optional dependency
            raise RuntimeError("Tkinter is required for --gui usage") from exc

        self.tk = tk
        self.ttk = ttk
        self.filedialog = filedialog
        self.messagebox = messagebox
        self.predictor = predictor or ThreatPredictor()
        self.root = tk.Tk()
        self.root.title("Advanced Penetration Testing Toolkit")
        self.root.geometry("900x650")
        self.queue: queue.Queue[str] = queue.Queue()

        self.server_var = tk.StringVar(value="127.0.0.1")
        self.port_var = tk.StringVar(value="55553")
        self.password_var = tk.StringVar()
        self.ssl_var = tk.BooleanVar(value=True)
        self.dry_run_var = tk.BooleanVar(value=True)

        self.target_var = tk.StringVar()
        self.exploit_var = tk.StringVar()
        self.payload_var = tk.StringVar()
        self.options_var = tk.StringVar()
        self.task_file_var = tk.StringVar()

        self.dataset_var = tk.StringVar()
        self.open_ports_var = tk.StringVar(value="5")
        self.vuln_var = tk.StringVar(value="3")
        self.exposure_var = tk.StringVar(value="0.5")
        self.criticality_var = tk.StringVar(value="0.4")

        self._build_layout()
        self.root.after(200, self._flush_queue)

    def _build_layout(self) -> None:
        tk = self.tk
        ttk = self.ttk

        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(4, weight=1)

        conn_frame = ttk.LabelFrame(self.root, text="RPC / Execution")
        conn_frame.grid(row=0, column=0, sticky="ew", padx=10, pady=5)
        for idx in range(6):
            conn_frame.columnconfigure(idx, weight=1)
        ttk.Label(conn_frame, text="Server").grid(row=0, column=0, sticky="w")
        ttk.Entry(conn_frame, textvariable=self.server_var, width=18).grid(row=1, column=0, sticky="ew", padx=2)
        ttk.Label(conn_frame, text="Port").grid(row=0, column=1, sticky="w")
        ttk.Entry(conn_frame, textvariable=self.port_var, width=8).grid(row=1, column=1, sticky="ew", padx=2)
        ttk.Label(conn_frame, text="Password").grid(row=0, column=2, sticky="w")
        ttk.Entry(conn_frame, textvariable=self.password_var, show="*").grid(row=1, column=2, sticky="ew", padx=2)
        ttk.Checkbutton(conn_frame, text="Use SSL", variable=self.ssl_var).grid(row=1, column=3, sticky="w")
        ttk.Checkbutton(conn_frame, text="Dry run", variable=self.dry_run_var).grid(row=1, column=4, sticky="w")

        task_frame = ttk.LabelFrame(self.root, text="Single Task Execution")
        task_frame.grid(row=1, column=0, sticky="ew", padx=10, pady=5)
        for idx in range(4):
            task_frame.columnconfigure(idx, weight=1)
        ttk.Label(task_frame, text="Target").grid(row=0, column=0, sticky="w")
        ttk.Entry(task_frame, textvariable=self.target_var).grid(row=1, column=0, sticky="ew", padx=2)
        ttk.Label(task_frame, text="Exploit").grid(row=0, column=1, sticky="w")
        ttk.Entry(task_frame, textvariable=self.exploit_var).grid(row=1, column=1, sticky="ew", padx=2)
        ttk.Label(task_frame, text="Payload").grid(row=0, column=2, sticky="w")
        ttk.Entry(task_frame, textvariable=self.payload_var).grid(row=1, column=2, sticky="ew", padx=2)
        ttk.Label(task_frame, text="Options (KEY=VALUE, comma separated)").grid(row=0, column=3, sticky="w")
        ttk.Entry(task_frame, textvariable=self.options_var).grid(row=1, column=3, sticky="ew", padx=2)
        ttk.Button(task_frame, text="Execute", command=self._run_single_task).grid(row=2, column=0, pady=5, sticky="w")

        batch_frame = ttk.LabelFrame(self.root, text="Batch Tasks")
        batch_frame.grid(row=2, column=0, sticky="ew", padx=10, pady=5)
        batch_frame.columnconfigure(1, weight=1)
        ttk.Label(batch_frame, text="Tasks file").grid(row=0, column=0, sticky="w")
        ttk.Entry(batch_frame, textvariable=self.task_file_var).grid(row=0, column=1, sticky="ew", padx=2)
        ttk.Button(batch_frame, text="Browse", command=self._browse_task_file).grid(row=0, column=2, padx=2)
        ttk.Button(batch_frame, text="Run file", command=self._run_task_file).grid(row=0, column=3, padx=2)

        ml_frame = ttk.LabelFrame(self.root, text="Machine Learning")
        ml_frame.grid(row=3, column=0, sticky="ew", padx=10, pady=5)
        for idx in range(6):
            ml_frame.columnconfigure(idx, weight=1)
        ttk.Label(ml_frame, text="Dataset").grid(row=0, column=0, sticky="w")
        ttk.Entry(ml_frame, textvariable=self.dataset_var).grid(row=0, column=1, columnspan=3, sticky="ew", padx=2)
        ttk.Button(ml_frame, text="Browse", command=self._browse_dataset).grid(row=0, column=4, padx=2)
        ttk.Button(ml_frame, text="Train", command=self._train_model).grid(row=0, column=5, padx=2)

        ttk.Label(ml_frame, text="Open ports").grid(row=1, column=0, sticky="w")
        ttk.Entry(ml_frame, textvariable=self.open_ports_var).grid(row=2, column=0, sticky="ew", padx=2)
        ttk.Label(ml_frame, text="Vuln count").grid(row=1, column=1, sticky="w")
        ttk.Entry(ml_frame, textvariable=self.vuln_var).grid(row=2, column=1, sticky="ew", padx=2)
        ttk.Label(ml_frame, text="Exposure score").grid(row=1, column=2, sticky="w")
        ttk.Entry(ml_frame, textvariable=self.exposure_var).grid(row=2, column=2, sticky="ew", padx=2)
        ttk.Label(ml_frame, text="Criticality").grid(row=1, column=3, sticky="w")
        ttk.Entry(ml_frame, textvariable=self.criticality_var).grid(row=2, column=3, sticky="ew", padx=2)
        ttk.Button(ml_frame, text="Predict", command=self._predict_from_gui).grid(row=2, column=4, padx=2, pady=5)

        log_frame = ttk.LabelFrame(self.root, text="Log output")
        log_frame.grid(row=4, column=0, sticky="nsew", padx=10, pady=5)
        log_frame.columnconfigure(0, weight=1)
        log_frame.rowconfigure(0, weight=1)
        self.log = tk.Text(log_frame, wrap="word", height=15)
        self.log.grid(row=0, column=0, sticky="nsew")
        scrollbar = ttk.Scrollbar(log_frame, orient="vertical", command=self.log.yview)
        scrollbar.grid(row=0, column=1, sticky="ns")
        self.log.configure(yscrollcommand=scrollbar.set)

    def run(self) -> None:
        self.root.mainloop()

    def _flush_queue(self) -> None:
        while True:
            try:
                message = self.queue.get_nowait()
            except queue.Empty:
                break
            self.log.insert("end", message + "\n")
            self.log.see("end")
        self.root.after(200, self._flush_queue)

    def _queue_message(self, message: str) -> None:
        self.queue.put(message)

    def _build_executor(self):
        if self.dry_run_var.get():
            return DryRunAutomator()
        password = self.password_var.get().strip()
        if not password:
            raise RuntimeError("Password is required unless dry-run is enabled")
        try:
            port = int(self.port_var.get() or 55553)
        except ValueError as exc:
            raise RuntimeError("Port must be an integer") from exc
        return AttackAutomator(
            password,
            server=self.server_var.get().strip() or "127.0.0.1",
            port=port,
            ssl=self.ssl_var.get(),
        )

    def _run_single_task(self) -> None:
        if not (self.target_var.get() and self.exploit_var.get() and self.payload_var.get()):
            self.messagebox.showerror("Missing fields", "Target, exploit, and payload are required")
            return
        try:
            options = self._options_from_string(self.options_var.get())
        except ValueError as exc:
            self.messagebox.showerror("Invalid options", str(exc))
            return
        task = AttackTask(
            target=self.target_var.get().strip(),
            exploit=self.exploit_var.get().strip(),
            payload=self.payload_var.get().strip(),
            options=options,
        )
        self._execute_tasks_async([task])

    def _execute_tasks_async(self, tasks: List[AttackTask]) -> None:
        thread = threading.Thread(target=self._execute_tasks, args=(tasks,), daemon=True)
        thread.start()

    def _execute_tasks(self, tasks: List[AttackTask]) -> None:
        try:
            executor = self._build_executor()
        except Exception as exc:  # pragma: no cover - GUI specific
            self._queue_message(f"[!] {exc}")
            return
        for task in tasks:
            try:
                result = executor.execute_task(task)
                self._queue_message(result.strip() or "(no output)")
            except Exception as exc:  # pragma: no cover - GUI specific
                self._queue_message(f"[!] Task failed: {exc}")

    def _browse_task_file(self) -> None:
        path = self.filedialog.askopenfilename(title="Select task JSON", filetypes=(("JSON", "*.json"), ("All", "*")))
        if path:
            self.task_file_var.set(path)

    def _run_task_file(self) -> None:
        if not self.task_file_var.get():
            self.messagebox.showerror("Missing file", "Select a JSON task file first")
            return
        try:
            tasks = _load_tasks_from_file(Path(self.task_file_var.get()))
        except Exception as exc:
            self.messagebox.showerror("Task error", str(exc))
            return
        self._execute_tasks_async(tasks)

    def _browse_dataset(self) -> None:
        path = self.filedialog.askopenfilename(title="Select dataset", filetypes=(("JSON", "*.json"), ("All", "*")))
        if path:
            self.dataset_var.set(path)

    def _train_model(self) -> None:
        if not self.dataset_var.get():
            self.messagebox.showerror("Missing dataset", "Select a dataset file first")
            return
        try:
            stats = self.predictor.train(Path(self.dataset_var.get()))
            self._queue_message(
                "[ML] Trained model on {samples} samples (backend={backend}, accuracy={accuracy:.2f})".format(
                    **stats
                )
            )
        except Exception as exc:
            self.messagebox.showerror("Training error", str(exc))

    def _predict_from_gui(self) -> None:
        features = {
            "open_ports": self.open_ports_var.get(),
            "vuln_count": self.vuln_var.get(),
            "exposure_score": self.exposure_var.get(),
            "criticality": self.criticality_var.get(),
        }
        try:
            parsed = {key: float(value) for key, value in features.items()}
            label, confidence = self.predictor.predict(parsed)
        except Exception as exc:
            self.messagebox.showerror("Prediction error", str(exc))
            return
        self._queue_message(f"[ML] Severity prediction: {label.upper()} (confidence={confidence:.2f})")

    @staticmethod
    def _options_from_string(raw: str) -> dict[str, str]:
        if not raw.strip():
            return {}
        cleaned = [chunk.strip() for chunk in raw.replace("\n", ",").split(",") if chunk.strip()]
        return _parse_options(cleaned)

def run_cli(argv: Sequence[str] | None = None) -> None:
    parser = _build_parser()
    args = parser.parse_args(argv)
    if args.max_delay < args.min_delay:
        parser.error("--max-delay must be greater than or equal to --min-delay")
    ml_requested = bool(args.ml_dataset or args.ml_predict)
    task_requested = bool(args.task or args.task_file)
    if not (task_requested or args.gui or ml_requested):
        parser.error("Supply --task/--task-file, --gui, or one of the ML options.")

    predictor: ThreatPredictor | None = None
    if args.gui or ml_requested:
        predictor = ThreatPredictor(model_path=args.ml_model)

    if args.ml_dataset:
        predictor = predictor or ThreatPredictor(model_path=args.ml_model)
        stats = predictor.train(args.ml_dataset)
        print(
            "[+] Trained ML model using {samples} samples (backend={backend}, accuracy={accuracy:.2f})".format(
                **stats
            )
        )
        if args.ml_model:
            predictor.save(args.ml_model)
            print(f"[+] Model persisted to {args.ml_model}")

    if args.ml_predict:
        predictor = predictor or ThreatPredictor(model_path=args.ml_model)
        if predictor.model is None and args.ml_model:
            predictor.load(args.ml_model)
        features = _parse_feature_pairs(args.ml_predict)
        label, confidence = predictor.predict(features)
        print(f"[+] Predicted severity: {label.upper()} (confidence={confidence:.2f})")

    if args.gui:
        launch_gui(predictor)
        return

    if not task_requested:
        return

    executor = _select_executor(args)
    tasks = _collect_tasks(args)
    records: list[dict[str, object]] = []
    for task in tasks:
        result = executor.execute_task(task)
        print(result)
        records.append(
            {
                "target": task.target,
                "exploit": task.exploit,
                "payload": task.payload,
                "options": task.options,
                "executed_at": datetime.utcnow().isoformat() + "Z",
                "output": result.strip(),
                "dry_run": bool(args.dry_run),
            }
        )
    if args.output:
        args.output.parent.mkdir(parents=True, exist_ok=True)
        args.output.write_text(json.dumps(records, indent=2), encoding="utf-8")
        print(f"[+] Execution log written to {args.output}")


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
    run_cli()
